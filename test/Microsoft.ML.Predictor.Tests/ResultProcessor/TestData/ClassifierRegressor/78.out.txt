maml.exe TrainTest test=F:\data\housing.txt tr=PoissonRegression{l2=0.1 l1=0 m=5 initwts=0.5} loader=TextLoader{col=Label:R4:0 col=Features:R4:1-13} data=F:\data\housing.txt
Automatically adding a MinMax normalization transform, use 'norm=Warn' or 'norm=No' to turn this behavior off.
Beginning optimization
   num vars: 14
   term criterion: Mean rel impr over 5 iter'ns < tol: 1.000e-7

Iter n: new_value (term_crit)
-------------------------------------------------
Iter 0: 5.2319e1 (**********) 
Iter 1: 1.2147e1 (...) --
Iter 2: 5.8074e0 (...) 
Iter 3: 5.4782e0 (...) 
Iter 4: 3.8058e0 (...) 
Iter 5: 3.6816e0 (...) 
Iter 6: 3.4762e0 (4.9888e-1) 
Iter 7: 3.2409e0 (1.5838e-1) -
Iter 8: 3.1604e0 (1.4668e-1) 
Iter 9: 3.1103e0 (4.4725e-2) 
Iter 10: 3.0042e0 (4.5101e-2) 
Iter 11: 2.9733e0 (3.3824e-2) -
Iter 12: 2.9618e0 (1.8843e-2) 
Iter 13: 2.9592e0 (1.3595e-2) 
Iter 14: 2.9548e0 (1.0521e-2) 
Iter 15: 2.9455e0 (3.9869e-3) 
Iter 16: 2.9355e0 (2.5798e-3) 
Iter 17: 2.9123e0 (3.4044e-3) 
Iter 18: 2.9047e0 (3.7536e-3) -
Iter 19: 2.8998e0 (3.7987e-3) 
Iter 20: 2.8864e0 (4.0890e-3) 
Iter 21: 2.8838e0 (3.5870e-3) 
Iter 22: 2.8778e0 (2.3974e-3) 
Iter 23: 2.8747e0 (2.0895e-3) 
Iter 24: 2.8661e0 (2.3476e-3) 
Iter 25: 2.8567e0 (2.0826e-3) 
Iter 26: 2.8515e0 (2.2633e-3) 
Iter 27: 2.8408e0 (2.5997e-3) 
Iter 28: 2.8396e0 (2.4697e-3) 
Iter 29: 2.8385e0 (1.9425e-3) 
Iter 30: 2.8365e0 (1.4266e-3) 
Iter 31: 2.8347e0 (1.1821e-3) 
Iter 32: 2.8324e0 (5.9448e-4) 
Iter 33: 2.8319e0 (5.4178e-4) -
Iter 34: 2.8299e0 (6.1389e-4) 
Iter 35: 2.8255e0 (7.7332e-4) 
Iter 36: 2.8227e0 (8.5520e-4) 
Iter 37: 2.8214e0 (7.8122e-4) 
Iter 38: 2.8198e0 (8.5768e-4) 
Iter 39: 2.8195e0 (7.3331e-4) 
Iter 40: 2.8189e0 (4.6958e-4) 
Iter 41: 2.8172e0 (3.9160e-4) -
Iter 42: 2.8161e0 (3.7495e-4) 
Iter 43: 2.8143e0 (3.8983e-4) 
Iter 44: 2.8120e0 (5.3150e-4) 
Iter 45: 2.8098e0 (6.4977e-4) 
Iter 46: 2.8093e0 (5.5781e-4) -
Iter 47: 2.8082e0 (5.6510e-4) -
Iter 48: 2.8072e0 (5.1041e-4) -
Iter 49: 2.8069e0 (3.6994e-4) 
Iter 50: 2.8067e0 (2.2127e-4) 
Iter 51: 2.8065e0 (2.0280e-4) 
Iter 52: 2.8063e0 (1.3104e-4) 
Iter 53: 2.8058e0 (9.9793e-5) 
Iter 54: 2.8049e0 (1.4090e-4) 
Iter 55: 2.8035e0 (2.2724e-4) -
Iter 56: 2.8030e0 (2.5096e-4) 
Iter 57: 2.8022e0 (2.9377e-4) 
Iter 58: 2.8014e0 (3.1238e-4) 
Iter 59: 2.8001e0 (3.3840e-4) -
Iter 60: 2.7996e0 (2.8042e-4) 
Iter 61: 2.7991e0 (2.7229e-4) 
Iter 62: 2.7989e0 (2.3879e-4) 
Iter 63: 2.7986e0 (2.0174e-4) 
Iter 64: 2.7985e0 (1.2050e-4) 
Iter 65: 2.7980e0 (1.0989e-4) 
Iter 66: 2.7978e0 (9.3260e-5) -
Iter 67: 2.7977e0 (8.2082e-5) 
Iter 68: 2.7975e0 (7.7726e-5) -
Iter 69: 2.7974e0 (7.2000e-5) 
Iter 70: 2.7974e0 (4.8001e-5) -
Iter 71: 2.7972e0 (4.9096e-5) 
Iter 72: 2.7969e0 (5.7283e-5) 
Iter 73: 2.7968e0 (5.2649e-5) -
Iter 74: 2.7967e0 (5.5652e-5) -
Iter 75: 2.7967e0 (5.0742e-5) 
Iter 76: 2.7966e0 (3.7375e-5) 
Iter 77: 2.7966e0 (2.5644e-5) 
Iter 78: 2.7965e0 (1.6096e-5) 
Iter 79: 2.7963e0 (2.8376e-5) -
Iter 80: 2.7962e0 (3.3288e-5) -
Iter 81: 2.7962e0 (3.1923e-5) 
Iter 82: 2.7962e0 (2.8922e-5) 
Iter 83: 2.7962e0 (2.5648e-5) 
Iter 84: 2.7962e0 (7.9127e-6) 
Iter 85: 2.7962e0 (3.0014e-6) --
Iter 86: 2.7961e0 (2.7285e-6) ---------- ------------------------------------------------------------------Not training a calibrator because it is not needed.
L1(avg):           2.80918485
L2(avg):           16.73567100
RMS(avg):          4.09092545
LOSS-FN(avg):      16.73567113

OVERALL RESULTS
---------------------------------------
L1(avg):             2.8092 (0.0000)
L2(avg):            16.7357 (0.0000)
RMS(avg):            4.0909 (0.0000)
LOSS-FN(avg):       16.7357 (0.0000)

---------------------------------------
2/2/2016 11:08:45 AM	 Time elapsed(s): 0.51

